{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drive Train Parameters\n",
    "\n",
    "As we design the alt-az mount, there are a bunch of options for designs, and the decision comes down to what kind of drive train we want to use.  That decision is in turn driven by the tracking precision needed in our system.  That, in turn, is decided by the optical parameters for exposure.\n",
    "\n",
    "First up, our field of view: this is a function of the F.O.V. (aka Angle Of View) equation: $\\frac{w}{f}\\cdot\\frac{180}{\\pi}$, with $w$ the width of the sensor, $f$ the focal length of the scope, and an angle small enough that the small angle approximation holds (otherwise there's a bit of trig in there).  In our case, $f = 1000\\textrm{mm}$, so this turns into simply $w_m \\textrm{rad}$.  For the Canon EOS APS-C sensor, $w = (22.3,14.9)\\textrm{mm}$, which leads to a FOV of (1.28°×0.85°)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.27769588,  0.85370711])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mm = 1000\n",
    "w_mm = np.array([22.3, 14.9])\n",
    "\n",
    "fov_deg = w_mm/f_mm * 180.0/np.pi\n",
    "fov_deg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing to consider is the pixels at work: our sensor is 4,752×3,168, which leads to a pixel pitch of 4.69µm in both directions.  We can either divide the FOV from the previous step by the pixels, or just use the pixel pitch.  Either way, we get an angular resolution of 0.97 arcseconds per pixel on our sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.96795143,  0.97012172]), 0.9673819412988819)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_px = np.array([4752,3168])\n",
    "angres1_px = fov_deg/w_px * 3600\n",
    "\n",
    "angres_px = 4.69e-6*180/np.pi * 3600\n",
    "\n",
    "angres1_px, angres_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we'd be thoroughly blessed to get seeing that's better than 3\", so 0.97\"/pixel means that our average feature is roughly a 3×3 pixel blotch on the sensor, which we'll factor in later.  For now, let's find out how far the objects are going to be moving, in pixels, during each exposure.\n",
    "\n",
    "We need to pull the average azimuthal speeds from `passes_to_parameters.ipynb` in this directory.  There, we get azimuthal rates with a median of 0.03573°/s and a mean of 0.152081°/s.  Applying Tukey inner fences, we get a mean of 0.05°/s, so the 0.15°/s is a pretty aggressive pass.  However, looking at ISS data, it seems that our mean is closer to 0.2°/s, so let's shoot for that.\n",
    "\n",
    "There is a wide range of exposure options here, so we'll look at that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display,HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Optics:\n",
    "    def __init__(self, nom, w_px,h_px, w_mm,h_mm, fps, f_mm):\n",
    "        self.nom = nom\n",
    "        self.px = np.array([w_px, h_px])\n",
    "        self.mm = np.array([w_mm, h_mm])\n",
    "        self.fps = fps\n",
    "        self.f_mm = f_mm\n",
    "        \n",
    "    def fov(self):\n",
    "        k = 180.0/np.pi * 1.0/self.f_mm\n",
    "        return k * self.mm\n",
    "    \n",
    "    def fov_px(self):\n",
    "        return self.fov()/self.px\n",
    "    \n",
    "    def px_per_frame(self, speed_degps):\n",
    "        return speed_degps/fps / self.fov_px()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_mm = 1000.0 # telescope holds this kinda constant...\n",
    "\n",
    "# Webcam looks to be a 1/3\" display: 4.8x3.6mm\n",
    "wcw_px = 4.8\n",
    "wch_px = 3.6\n",
    "\n",
    "f_mm = 1000.0\n",
    "\n",
    "optics = [\n",
    "    Optics(\"Canon 500D 1080p\", 1920,1080, 22.3,14.9, 20.0, f_mm),\n",
    "    Optics(\"Canon 500D 720p\",  1280, 720, 22.3,14.9, 30.0, f_mm),\n",
    "    Optics(\"Canon 500D 1/3\",   4752,3168, 22.3,14.9,  3.0, f_mm),\n",
    "    Optics(\"Webcam VGA\",        640, 480, wcw_px,wch_px, 30.0, f_mm),\n",
    "    Optics(\"Webcam SVGA\",       800, 600, wcw_px,wch_px, 20.0, f_mm),\n",
    "    Optics(\"Webcam UVGA\",       1280, 960, wcw_px,wch_px,  9.0, f_mm),\n",
    "    Optics(\"Webcam UXGA\",      1600,1200, wcw_px,wch_px,  5.0, f_mm),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Camera</th><th>FPS</th><th>FOVs/sec</th><th>Pixels/Frame</th><th>FOV/px</th></tr><tr><td>Canon 500D 1080p</td><td>20.0</td><td>0.156531771479</td><td>60.1082002481</td><td>0.000665466605803</td></tr><tr><td>Canon 500D 720p</td><td>30.0</td><td>0.156531771479</td><td>40.0721334987</td><td>0.000998199908704</td></tr><tr><td>Canon 500D 1/3</td><td>3.0</td><td>0.156531771479</td><td>148.767795614</td><td>0.000268875396284</td></tr><tr><td>Webcam VGA</td><td>30.0</td><td>0.727220521664</td><td>93.084226773</td><td>0.000429718346348</td></tr><tr><td>Webcam SVGA</td><td>20.0</td><td>0.727220521664</td><td>116.355283466</td><td>0.000343774677078</td></tr><tr><td>Webcam UVGA</td><td>9.0</td><td>0.727220521664</td><td>186.168453546</td><td>0.000214859173174</td></tr><tr><td>Webcam UXGA</td><td>5.0</td><td>0.727220521664</td><td>232.710566933</td><td>0.000171887338539</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "speed_degps = 0.2\n",
    "\n",
    "# This gets more complicated with resolutions, though, so we'll factor that in\n",
    "\n",
    "\n",
    "table = \"<table><tr>\" + \"\".join([\"<th>%s</th>\" % s for s in \"Camera FPS FOVs/sec Pixels/Frame FOV/px\".split() ]) + \"</tr>\"\n",
    "\n",
    "for o in optics:\n",
    "    row = o.nom, o.fps, speed_degps/o.fov()[0], o.px_per_frame(speed_degps)[0], o.fov_px()[0]\n",
    "    table += \"<tr><td>\" + \"</td><td>\".join(map(str, row)) + \"</td></tr>\"\n",
    "    \n",
    "table += \"</table>\"\n",
    "display(HTML(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm starting to think that this is all inside out, and I should be starting with the precision of the TLEs and sorting out the range of field I need to be able to see in order to best assess their validity… the above is all about the direct imaging case, but that's possibly beyond my current equipment anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closed loop sensor precision\n",
    "\n",
    "Another question that occurs to me: how precise do my sensors need to be to track things accurately?  Let's start with the most demanding case: pixel-perfect tracking.\n",
    "\n",
    "There are actually two questions here, one for altitude and the other for azimuth.  We'll assume the camera sensor is arranged in \"landscape\" mode, and focus on the azimuth case, as its markedly harder than the altitude case.\n",
    "\n",
    "(Why is it so much harder?  While the sensor is 33% bigger, it needs to cover 360° of azimuth, while the altitude only has to go from 0° to 90°.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Camera</th><th>arcsec/px</th><th>Total steps</th></tr><tr><td>Canon 500D 1080p</td><td>2.39567978089</td><td>540973</td></tr><tr><td>Canon 500D 720p</td><td>3.59351967134</td><td>360649</td></tr><tr><td>Canon 500D 1/3</td><td>0.967951426623</td><td>1338910</td></tr><tr><td>Webcam VGA</td><td>1.54698604685</td><td>837758</td></tr><tr><td>Webcam SVGA</td><td>1.23758883748</td><td>1047197</td></tr><tr><td>Webcam UVGA</td><td>0.773493023427</td><td>1675516</td></tr><tr><td>Webcam UXGA</td><td>0.618794418741</td><td>2094395</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = \"<table><tr><th>\" + \"</th><th>\".join([\"Camera\", \"arcsec/px\", \"Total steps\"]) + \"</th></tr>\"\n",
    "\n",
    "for o in optics:\n",
    "    row = [ o.nom, o.fov_px()[0]*3600, int(360.0/o.fov_px()[0]) ]\n",
    "    table += \"<tr>\" + \"\".join([\"<td>%s</td>\" % s for s in map(str, row) ]) + \"</tr>\"\n",
    "\n",
    "table += \"</table>\"\n",
    "display(HTML(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, so... that seems unlikely to happen.  Two million steps per revolution is rather a lot, no matter what the control system is.  Random question: what kind of gearing ratio is that for a stepper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10471.975511965977"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_steps = 360.0/(optics[-1].fov_px()[0])\n",
    "\n",
    "steps_per_rev = 200 # typical 1.8deg steps\n",
    "\n",
    "target_steps/steps_per_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10,000:1 is kind of a lot.  Though it's possible to microstep 10:1 (GeckoDrives), which leaves us with 1000:1, which is a couple of 30:1 reductions cascaded.  It's not impossible to get that precision with steppers.\n",
    "\n",
    "What about the other end of the precision scale: getting to within a third of the frame (going to \"within half a frame\" means that the object may be on the edge of the frame instead of in the center, so let's go with 3x) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Camera</th><th>arcsec/frame</th><th>Total steps</th></tr><tr><td>Canon 500D 1080p</td><td>1533.23505977</td><td>845</td></tr><tr><td>Canon 500D 720p</td><td>1533.23505977</td><td>845</td></tr><tr><td>Canon 500D 1/3</td><td>1533.23505977</td><td>845</td></tr><tr><td>Webcam VGA</td><td>330.023689995</td><td>3926</td></tr><tr><td>Webcam SVGA</td><td>330.023689995</td><td>3926</td></tr><tr><td>Webcam UVGA</td><td>330.023689995</td><td>3926</td></tr><tr><td>Webcam UXGA</td><td>330.023689995</td><td>3926</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = \"<table><tr><th>\" + \"</th><th>\".join([\"Camera\", \"arcsec/frame\", \"Total steps\"]) + \"</th></tr>\"\n",
    "\n",
    "for o in optics:\n",
    "    r = o.fov()[0]/3\n",
    "    row = [ o.nom, r*3600, int(360.0/r) ]\n",
    "    table += \"<tr>\" + \"\".join([\"<td>%s</td>\" % s for s in map(str, row) ]) + \"</tr>\"\n",
    "\n",
    "table += \"</table>\"\n",
    "display(HTML(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, this is only a bit better: we still need gearing to get this resolution with steppers.  Admittedly, it's a much more manageable 20:1 or so.  Now for the fun question: how many pixels wide is a given step at various gearing ratios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><caption>Pixels per step, at various gear ratios</caption><tr><th>Camera</th><th>1</th><th>3</th><th>5</th><th>10</th><th>20</th><th>30</th><th>50</th><th>100</th><th>200</th><th>500</th><th>1000</th><th>3000</th><th>10000</th></tr><tr><td>Canon 500D 1080p</td><td>2704.9</td><td>901.6</td><td>541.0</td><td>270.5</td><td>135.2</td><td>90.2</td><td>54.1</td><td>27.0</td><td>13.5</td><td>5.4</td><td>2.7</td><td>0.9</td><td>0.3</td></tr><tr><td>Canon 500D 720p</td><td>1803.2</td><td>601.1</td><td>360.6</td><td>180.3</td><td>90.2</td><td>60.1</td><td>36.1</td><td>18.0</td><td>9.0</td><td>3.6</td><td>1.8</td><td>0.6</td><td>0.2</td></tr><tr><td>Canon 500D 1/3</td><td>6694.6</td><td>2231.5</td><td>1338.9</td><td>669.5</td><td>334.7</td><td>223.2</td><td>133.9</td><td>66.9</td><td>33.5</td><td>13.4</td><td>6.7</td><td>2.2</td><td>0.7</td></tr><tr><td>Webcam VGA</td><td>4188.8</td><td>1396.3</td><td>837.8</td><td>418.9</td><td>209.4</td><td>139.6</td><td>83.8</td><td>41.9</td><td>20.9</td><td>8.4</td><td>4.2</td><td>1.4</td><td>0.4</td></tr><tr><td>Webcam SVGA</td><td>5236.0</td><td>1745.3</td><td>1047.2</td><td>523.6</td><td>261.8</td><td>174.5</td><td>104.7</td><td>52.4</td><td>26.2</td><td>10.5</td><td>5.2</td><td>1.7</td><td>0.5</td></tr><tr><td>Webcam UVGA</td><td>8377.6</td><td>2792.5</td><td>1675.5</td><td>837.8</td><td>418.9</td><td>279.3</td><td>167.6</td><td>83.8</td><td>41.9</td><td>16.8</td><td>8.4</td><td>2.8</td><td>0.8</td></tr><tr><td>Webcam UXGA</td><td>10472.0</td><td>3490.7</td><td>2094.4</td><td>1047.2</td><td>523.6</td><td>349.1</td><td>209.4</td><td>104.7</td><td>52.4</td><td>20.9</td><td>10.5</td><td>3.5</td><td>1.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratios = [1, 3, 5, 10, 20, 30, 50, 100, 200, 500, 1000, 3000, 10000 ]\n",
    "\n",
    "table = \"<table><caption>Pixels per step, at various gear ratios</caption>\"\n",
    "table += \"<tr><th>\" + \"</th><th>\".join([\"Camera\"] + map(str, ratios)) + \"</th></tr>\"\n",
    "\n",
    "for o in optics:    \n",
    "    r = o.fov_px()[0]\n",
    "    row = [ o.nom ] + [ \"%0.1f\" % (360.0/(200.0*ratio) / r) for ratio in ratios ]\n",
    "    table += \"<tr>\" + \"\".join([\"<td>%s</td>\" % s for s in map(str, row) ]) + \"</tr>\"\n",
    "\n",
    "table += \"</table>\"\n",
    "display(HTML(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><caption>Fraction of sensor per step, at various gear ratios</caption><tr><th>Camera</th><th>1</th><th>3</th><th>5</th><th>10</th><th>20</th><th>30</th><th>50</th><th>100</th><th>200</th><th>500</th><th>1000</th><th>3000</th><th>10000</th></tr><tr><td>Canon 500D 1080p</td><td>1.4088</td><td>0.4696</td><td>0.2818</td><td>0.1409</td><td>0.0704</td><td>0.0470</td><td>0.0282</td><td>0.0141</td><td>0.0070</td><td>0.0028</td><td>0.0014</td><td>0.0005</td><td>0.0001</td></tr><tr><td>Canon 500D 720p</td><td>1.4088</td><td>0.4696</td><td>0.2818</td><td>0.1409</td><td>0.0704</td><td>0.0470</td><td>0.0282</td><td>0.0141</td><td>0.0070</td><td>0.0028</td><td>0.0014</td><td>0.0005</td><td>0.0001</td></tr><tr><td>Canon 500D 1/3</td><td>1.4088</td><td>0.4696</td><td>0.2818</td><td>0.1409</td><td>0.0704</td><td>0.0470</td><td>0.0282</td><td>0.0141</td><td>0.0070</td><td>0.0028</td><td>0.0014</td><td>0.0005</td><td>0.0001</td></tr><tr><td>Webcam VGA</td><td>6.5450</td><td>2.1817</td><td>1.3090</td><td>0.6545</td><td>0.3272</td><td>0.2182</td><td>0.1309</td><td>0.0654</td><td>0.0327</td><td>0.0131</td><td>0.0065</td><td>0.0022</td><td>0.0007</td></tr><tr><td>Webcam SVGA</td><td>6.5450</td><td>2.1817</td><td>1.3090</td><td>0.6545</td><td>0.3272</td><td>0.2182</td><td>0.1309</td><td>0.0654</td><td>0.0327</td><td>0.0131</td><td>0.0065</td><td>0.0022</td><td>0.0007</td></tr><tr><td>Webcam UVGA</td><td>6.5450</td><td>2.1817</td><td>1.3090</td><td>0.6545</td><td>0.3272</td><td>0.2182</td><td>0.1309</td><td>0.0654</td><td>0.0327</td><td>0.0131</td><td>0.0065</td><td>0.0022</td><td>0.0007</td></tr><tr><td>Webcam UXGA</td><td>6.5450</td><td>2.1817</td><td>1.3090</td><td>0.6545</td><td>0.3272</td><td>0.2182</td><td>0.1309</td><td>0.0654</td><td>0.0327</td><td>0.0131</td><td>0.0065</td><td>0.0022</td><td>0.0007</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = \"<table><caption>Fraction of sensor per step, at various gear ratios</caption>\"\n",
    "table += \"<tr><th>\" + \"</th><th>\".join([\"Camera\"] + map(str, ratios)) + \"</th></tr>\"\n",
    "\n",
    "for o in optics:    \n",
    "    r = o.fov()[0]\n",
    "    row = [ o.nom ] + [ \"%0.4f\" % (360.0/(200.0*ratio) / r) for ratio in ratios ]\n",
    "    table += \"<tr>\" + \"\".join([\"<td>%s</td>\" % s for s in map(str, row) ]) + \"</tr>\"\n",
    "\n",
    "table += \"</table>\"\n",
    "display(HTML(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><caption>Arcseconds per step, at various gear ratios</caption><tr><th>1</th><th>3</th><th>5</th><th>10</th><th>20</th><th>30</th><th>50</th><th>100</th><th>200</th><th>500</th><th>1000</th><th>3000</th><th>10000</th></tr><tr><td>6480.00</td><td>2160.00</td><td>1296.00</td><td>648.00</td><td>324.00</td><td>216.00</td><td>129.60</td><td>64.80</td><td>32.40</td><td>12.96</td><td>6.48</td><td>2.16</td><td>0.65</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = \"<table><caption>Arcseconds per step, at various gear ratios</caption>\"\n",
    "table += \"<tr><th>\" + \"</th><th>\".join(map(str, ratios)) + \"</th></tr>\"\n",
    "\n",
    "row = [ \"%0.2f\" % (360.0*3600/(200.0*ratio)) for ratio in ratios ]\n",
    "table += \"<tr>\" + \"\".join([\"<td>%s</td>\" % s for s in map(str, row) ]) + \"</tr>\"\n",
    "\n",
    "table += \"</table>\"\n",
    "display(HTML(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think a key takeaway here is that it takes 1,000:1 gearing just to get into the ballpark of good seeing.  That's going to be a many step geartrain (unless I get really goofy), which means that it will have its own backlash/slop.  This is going to vary with the angle the scope is at etc, which makes for a bit of a control mess.\n",
    "\n",
    "There are planetary gearboxes available on NEMA steppers at reasonable prices, all the way up to 100:1 ratios, which means that we might be able to get to something like 3,000:1 with a subsequent stage, with relatively tight amounts of slop.\n",
    "\n",
    "Whatever the outcome: this level of control looks particularly hairy, and means we definitely have to work with steps that are much much larger than our targets. This precludes the idea of tracking an object within a set of pixels, and forces a much more slew, capture, slew, capture sort of affair."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
